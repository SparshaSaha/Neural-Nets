{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d,max_pool_2d\n",
    "from tflearn.layers.core import input_data,dropout,fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "from PIL import Image\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOADING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil=scipy.io.loadmat('ex3data1.mat')\n",
    "y_data=fil.get('y')\n",
    "x_data=fil.get('X')\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "\n",
    "for i in range(0,400):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(400,500):\n",
    "    x_test.append(x_data[i])\n",
    "\n",
    "for i in range(500,900):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(900,1000):\n",
    "    x_test.append(x_data[i])\n",
    "\n",
    "for i in range(1000,1400):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(1400,1500):\n",
    "    x_test.append(x_data[i])\n",
    "\n",
    "for i in range(1500,1900):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(1900,2000):\n",
    "    x_test.append(x_data[i])\n",
    "\n",
    "for i in range(2000,2400):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(2400,2500):\n",
    "    x_test.append(x_data[i])\n",
    "    \n",
    "for i in range(2500,2900):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(2900,3000):\n",
    "    x_test.append(x_data[i])\n",
    "\n",
    "for i in range(3000,3400):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(3400,3500):\n",
    "    x_test.append(x_data[i])\n",
    "\n",
    "for i in range(3500,3900):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(3900,4000):\n",
    "    x_test.append(x_data[i])\n",
    "\n",
    "for i in range(4000,4400):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(4400,4500):\n",
    "    x_test.append(x_data[i])\n",
    "    \n",
    "for i in range(4500,4900):\n",
    "    x_train.append(x_data[i])\n",
    "for i in range(4900,5000):\n",
    "    x_test.append(x_data[i])\n",
    "    \n",
    "z=[]\n",
    "zp=[]\n",
    "for i in x_train:\n",
    "    m=np.array(i)\n",
    "    y=m.reshape(20,20,1)\n",
    "    z.append(y.tolist())\n",
    "    zp.append(m.reshape(20,20).tolist())\n",
    "\n",
    "z=np.array(z)\n",
    "x_train=z\n",
    "\n",
    "\n",
    "z=[]\n",
    "\n",
    "for i in x_test:\n",
    "    y=np.array(i)\n",
    "    y=y.reshape(20,20,1)\n",
    "    z.append(y.tolist())\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "z=np.array(z)\n",
    "x_test=z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=[]\n",
    "for i in range(400):\n",
    "    y_data.append([0,0,0,0,0,0,0,0,0,1])\n",
    "for i in range(400):   \n",
    "    y_data.append([1,0,0,0,0,0,0,0,0,0])\n",
    "for i in range(400):\n",
    "    y_data.append([0,1,0,0,0,0,0,0,0,0])\n",
    "for i in range(400):\n",
    "    y_data.append([0,0,1,0,0,0,0,0,0,0])\n",
    "for i in range(400):\n",
    "    y_data.append([0,0,0,1,0,0,0,0,0,0])\n",
    "for i in range(400):\n",
    "    y_data.append([0,0,0,0,1,0,0,0,0,0])\n",
    "for i in range(400):\n",
    "    y_data.append([0,0,0,0,0,1,0,0,0,0])\n",
    "for i in range(400):\n",
    "    y_data.append([0,0,0,0,0,0,1,0,0,0])\n",
    "for i in range(400):\n",
    "    y_data.append([0,0,0,0,0,0,0,1,0,0])\n",
    "for i in range(400):\n",
    "    y_data.append([0,0,0,0,0,0,0,0,1,0])\n",
    "\n",
    "#Test Data y\n",
    "y_data_test=[]\n",
    "for i in range(100):\n",
    "    y_data_test.append([0,0,0,0,0,0,0,0,0,1])\n",
    "for i in range(100):   \n",
    "    y_data_test.append([1,0,0,0,0,0,0,0,0,0])\n",
    "for i in range(100):\n",
    "    y_data_test.append([0,1,0,0,0,0,0,0,0,0])\n",
    "for i in range(100):\n",
    "    y_data_test.append([0,0,1,0,0,0,0,0,0,0])\n",
    "for i in range(100):\n",
    "    y_data_test.append([0,0,0,1,0,0,0,0,0,0])\n",
    "for i in range(100):\n",
    "    y_data_test.append([0,0,0,0,1,0,0,0,0,0])\n",
    "for i in range(100):\n",
    "    y_data_test.append([0,0,0,0,0,1,0,0,0,0])\n",
    "for i in range(100):\n",
    "    y_data_test.append([0,0,0,0,0,0,1,0,0,0])\n",
    "for i in range(100):\n",
    "    y_data_test.append([0,0,0,0,0,0,0,1,0,0])\n",
    "for i in range(100):\n",
    "    y_data_test.append([0,0,0,0,0,0,0,0,1,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE GRAPH AND CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/initializations.py:119: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "convnet=input_data(shape=[None,20,20,1],name='input')\n",
    "convnet=conv_2d(convnet,32,2,activation='relu')\n",
    "convnet=max_pool_2d(convnet,2)\n",
    "convnet=conv_2d(convnet,64,2,activation='relu')\n",
    "convnet=max_pool_2d(convnet,2)\n",
    "\n",
    "convnet=conv_2d(convnet,128,2,activation='relu')\n",
    "convnet=max_pool_2d(convnet,2)\n",
    "\n",
    "convnet=conv_2d(convnet,256,2,activation='relu')\n",
    "convnet=max_pool_2d(convnet,2)\n",
    "\n",
    "convnet=conv_2d(convnet,128,2,activation='relu')\n",
    "convnet=max_pool_2d(convnet,2)\n",
    "\n",
    "convnet=conv_2d(convnet,64,2,activation='relu')\n",
    "convnet=max_pool_2d(convnet,2)\n",
    "\n",
    "convnet=fully_connected(convnet,1024,activation='relu')\n",
    "convnet=dropout(convnet,0.8)\n",
    "\n",
    "convnet=fully_connected(convnet,10,activation='softmax')\n",
    "\n",
    "convnet=regression(convnet,optimizer='adam',learning_rate=0.002,loss='categorical_crossentropy',name='regression')\n",
    "\n",
    "model=tflearn.DNN(convnet,tensorboard_verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING STEP....TAKES TIME>>>LOAD THE THE TRAINED MODEL ITSELF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m0.06696\u001b[0m\u001b[0m | time: 6.641s\n",
      "\u001b[2K\r",
      "| Adam | epoch: 015 | loss: 0.06696 - acc: 0.9840 -- iter: 3520/4000\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_data, n_epoch=20,\n",
    "           validation_set=(x_test, y_data_test),\n",
    "           snapshot_step=100, show_metric=True, run_id='convnet_coursera')\n",
    "\n",
    "model.save(\"cnn_model.tfl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL LOAD AND PREDICT AND VISUALIZE IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/sparsha/gitprojects/Neural Networks/Coursera Handwritten digits Recognition/cnn_model.tfl\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [2,2,1,32] rhs shape= [5,5,1,32]\n\t [[Node: save_1/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Conv2D/W\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Conv2D/W/Adam, save_1/RestoreV2_4)]]\n\nCaused by op u'save_1/Assign_4', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-0f8fac7ed539>\", line 27, in <module>\n    model=tflearn.DNN(convnet,tensorboard_verbose=0)\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/models/dnn.py\", line 65, in __init__\n    best_val_accuracy=best_val_accuracy)\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py\", line 147, in __init__\n    allow_empty=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1239, in __init__\n    self.build()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1248, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1284, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 765, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 440, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 160, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [2,2,1,32] rhs shape= [5,5,1,32]\n\t [[Node: save_1/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Conv2D/W\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Conv2D/W/Adam, save_1/RestoreV2_4)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7368d076c54e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cnn_model.tfl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2364\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m250000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tflearn/models/dnn.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, model_file, weights_only, **optargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m                      \u001b[0mcreated\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrestored\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \"\"\"\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         self.predictor = Evaluator([self.net],\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, model_file, trainable_variable_only, variable_name_map, scope_for_restore, create_new_session, verbose)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mrestorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrainable_variable_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestorer_trainvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1684\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1686\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1687\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [2,2,1,32] rhs shape= [5,5,1,32]\n\t [[Node: save_1/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Conv2D/W\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Conv2D/W/Adam, save_1/RestoreV2_4)]]\n\nCaused by op u'save_1/Assign_4', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib/python2.7/dist-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib/python2.7/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-0f8fac7ed539>\", line 27, in <module>\n    model=tflearn.DNN(convnet,tensorboard_verbose=0)\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/models/dnn.py\", line 65, in __init__\n    best_val_accuracy=best_val_accuracy)\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py\", line 147, in __init__\n    allow_empty=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1239, in __init__\n    self.build()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1248, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1284, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 765, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 440, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 160, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 59, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [2,2,1,32] rhs shape= [5,5,1,32]\n\t [[Node: save_1/Assign_4 = Assign[T=DT_FLOAT, _class=[\"loc:@Conv2D/W\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Conv2D/W/Adam, save_1/RestoreV2_4)]]\n"
     ]
    }
   ],
   "source": [
    "model.load(\"cnn_model.tfl\")\n",
    "c=2364\n",
    "predict=model.predict([x_train[c]])\n",
    "maximum=-250000\n",
    "max_index=0\n",
    "for i in range(len(predict[0])):\n",
    "    if predict[0][i]>maximum:\n",
    "        maximum=predict[0][i]\n",
    "        max_index=i\n",
    "\n",
    "if max_index==9:\n",
    "    print(0)\n",
    "else:\n",
    "    print(max_index+1)\n",
    "\n",
    "\n",
    "x=zp[c]\n",
    "\n",
    "x=np.matrix(x)\n",
    "x=x.transpose()\n",
    "pyplot.imshow(x,cmap=cm.gray_r)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
