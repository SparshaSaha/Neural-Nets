{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#define the network\n",
    "nodes_input=2\n",
    "nodes_hidden_1=2\n",
    "nodes_output=1\n",
    "\n",
    "batch_size=1;\n",
    "\n",
    "x=tf.placeholder('float',[None,2])\n",
    "y=tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(xh):     #function to read data from file\n",
    "    datafile=open(xh,\"r\")\n",
    "    datalist=[]\n",
    "    for line in datafile:\n",
    "        z=line.split(\",\")\n",
    "        xg=[float(i) for i in z]\n",
    "        datalist.append(xg)\n",
    "    f=np.matrix(datalist)\n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor_nn(data):\n",
    "    \n",
    "    #Define weights for neural network\n",
    "    hidden_l1={'weights':tf.Variable(tf.random_normal([nodes_input,nodes_hidden_1])),'biases':tf.Variable(tf.random_normal([nodes_hidden_1]))}\n",
    "    \n",
    "    output_layer={'weights':tf.Variable(tf.random_normal([nodes_hidden_1,nodes_output])),'biases':tf.Variable(tf.random_normal([nodes_output]))}\n",
    "    \n",
    "    #feed forward throught the network\n",
    "    l1=tf.add(tf.matmul(data,hidden_l1['weights']),hidden_l1['biases'])\n",
    "    l1=tf.nn.relu(l1)\n",
    "    \n",
    "    output=tf.add(tf.matmul(l1,output_layer['weights']),output_layer['biases'])\n",
    "    \n",
    "    output=tf.nn.relu(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(ox):\n",
    "    prediction=xor_nn(ox)\n",
    "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "    \n",
    "    optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    hm_epochs=30\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            loss=0;\n",
    "            for d in range(4/batch_size):\n",
    "                new_x,new_y=get_epoch_batch(d)\n",
    "                _,c=sess.run([optimizer,cost],feed_dict={x:new_x,y:new_y})\n",
    "                loss+=c\n",
    "            \n",
    "            print('Epoch ',epoch,' Completed ',hm_epochs)\n",
    "        \n",
    "        correct=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "        \n",
    "        print(\"Model trained\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_batch(batch_size):\n",
    "    x_0=ox[batch_size]\n",
    "    y_0=oy[batch_size]\n",
    "    x_1=np.asarray([x_0])\n",
    "    y_1=np.asarray([y_0])\n",
    "    \n",
    "    return x_1,y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch ', 0, ' Completed ', 30)\n",
      "('Epoch ', 1, ' Completed ', 30)\n",
      "('Epoch ', 2, ' Completed ', 30)\n",
      "('Epoch ', 3, ' Completed ', 30)\n",
      "('Epoch ', 4, ' Completed ', 30)\n",
      "('Epoch ', 5, ' Completed ', 30)\n",
      "('Epoch ', 6, ' Completed ', 30)\n",
      "('Epoch ', 7, ' Completed ', 30)\n",
      "('Epoch ', 8, ' Completed ', 30)\n",
      "('Epoch ', 9, ' Completed ', 30)\n",
      "('Epoch ', 10, ' Completed ', 30)\n",
      "('Epoch ', 11, ' Completed ', 30)\n",
      "('Epoch ', 12, ' Completed ', 30)\n",
      "('Epoch ', 13, ' Completed ', 30)\n",
      "('Epoch ', 14, ' Completed ', 30)\n",
      "('Epoch ', 15, ' Completed ', 30)\n",
      "('Epoch ', 16, ' Completed ', 30)\n",
      "('Epoch ', 17, ' Completed ', 30)\n",
      "('Epoch ', 18, ' Completed ', 30)\n",
      "('Epoch ', 19, ' Completed ', 30)\n",
      "('Epoch ', 20, ' Completed ', 30)\n",
      "('Epoch ', 21, ' Completed ', 30)\n",
      "('Epoch ', 22, ' Completed ', 30)\n",
      "('Epoch ', 23, ' Completed ', 30)\n",
      "('Epoch ', 24, ' Completed ', 30)\n",
      "('Epoch ', 25, ' Completed ', 30)\n",
      "('Epoch ', 26, ' Completed ', 30)\n",
      "('Epoch ', 27, ' Completed ', 30)\n",
      "('Epoch ', 28, ' Completed ', 30)\n",
      "('Epoch ', 29, ' Completed ', 30)\n",
      "Model trained\n",
      "<tf.Variable 'Variable_1:0' shape=(2,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "ox=get_data(\"x_data.txt\")\n",
    "oy=get_data(\"y_data.txt\")\n",
    "train_neural_network(x)\n",
    "\n",
    "vars=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "w1=p[0]\n",
    "b1=p[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
